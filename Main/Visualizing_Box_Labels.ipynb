{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Upload your files here.**"
      ],
      "metadata": {
        "id": "v6K5pRzRbIKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploads = files.upload()"
      ],
      "metadata": {
        "id": "iMuFX_62a3XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Met Oddy Test CNN\n",
        "\n",
        "This code will prepare the model, it only has to be run once."
      ],
      "metadata": {
        "id": "hLxVsAd06q3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Process Inputs\n",
        "\n",
        "**Run this if you want to clear old files before uploading more.**"
      ],
      "metadata": {
        "id": "rAGbawHa82L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add folder for input images\n",
        "!rm -rf input_images\n",
        "!mkdir input_images\n",
        "# Make directory for outputted images\n",
        "!rm -rf result_directory\n",
        "!mkdir result_directory"
      ],
      "metadata": {
        "id": "AAB_OgAc81I8"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "JW9GJ0XlYl84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaf85e1-5cff-4910-db77-c05f12cb8d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done moving!\n"
          ]
        }
      ],
      "source": [
        "# Sets up the ability to ask for files\n",
        "import os\n",
        "\n",
        "# Asks you to upload a file\n",
        "for i in uploads.keys():\n",
        "  if ' ' in i:\n",
        "    os.rename(\"/content/\"+i, \"/content/\"+i.replace(\" \",\"_\"))\n",
        "  i = i.replace(\" \",\"_\")\n",
        "  file = \"/content/\"+i\n",
        "  !mv $file \"/content/input_images\"\n",
        "print(\"Done moving!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following Python notebook will run an inputted batch of images through a trained convolutional neural network to predict the corrosion level in Oddy Test images. There a few things you will need to do to set up this notebook. \n",
        "\n",
        "Click on the play button on the left hand side of the code boxes to run the code.\n",
        "\n",
        "## Prepare files"
      ],
      "metadata": {
        "id": "D8ZavgjS6wdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Get checkpoint files"
      ],
      "metadata": {
        "id": "SWMhesWh6WxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/fredthefish/OddyTest/main/checkpoint -P MetCheckpoint\n",
        "!wget https://raw.githubusercontent.com/fredthefish/OddyTest/main/ckpt-49.index -P MetCheckpoint\n",
        "!wget https://raw.githubusercontent.com/fredthefish/OddyTest/main/ckpt-49.data-00000-of-00001 -P MetCheckpoint\n",
        "\n",
        "checkpoint_path = '/content/MetCheckpoint/ckpt-49'"
      ],
      "metadata": {
        "id": "WdoGAG966k1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2803e4b-c163-4aee-a90a-b6b5f7f86576"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-18 17:56:44--  https://raw.githubusercontent.com/fredthefish/OddyTest/main/checkpoint\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 706 [text/plain]\n",
            "Saving to: ‘MetCheckpoint/checkpoint’\n",
            "\n",
            "checkpoint          100%[===================>]     706  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-18 17:56:45 (29.2 MB/s) - ‘MetCheckpoint/checkpoint’ saved [706/706]\n",
            "\n",
            "--2022-08-18 17:56:45--  https://raw.githubusercontent.com/fredthefish/OddyTest/main/ckpt-49.index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114788 (112K) [application/octet-stream]\n",
            "Saving to: ‘MetCheckpoint/ckpt-49.index’\n",
            "\n",
            "ckpt-49.index       100%[===================>] 112.10K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-08-18 17:56:45 (4.85 MB/s) - ‘MetCheckpoint/ckpt-49.index’ saved [114788/114788]\n",
            "\n",
            "--2022-08-18 17:56:45--  https://raw.githubusercontent.com/fredthefish/OddyTest/main/ckpt-49.data-00000-of-00001\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66477779 (63M) [application/octet-stream]\n",
            "Saving to: ‘MetCheckpoint/ckpt-49.data-00000-of-00001’\n",
            "\n",
            "ckpt-49.data-00000- 100%[===================>]  63.40M   145MB/s    in 0.4s    \n",
            "\n",
            "2022-08-18 17:56:47 (145 MB/s) - ‘MetCheckpoint/ckpt-49.data-00000-of-00001’ saved [66477779/66477779]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "## 2. Prepare the Model\n",
        "\n",
        "Prepares the model. This code only has to be run once. Note that it may take 10 minutes to complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "### 2.1 Install TensorFlow and Object Detection API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFAOOC8Ka00r",
        "outputId": "7a888155-1dd8-4eab-8aed-de0cd3e8ce26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (4.1.1)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.26.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.47.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (14.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (21.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.17.3)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.9.1) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow==2.9.1) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow latest version\n",
        "# !pip install --upgrade tensorflow\n",
        "!pip install -U --pre tensorflow==\"2.9.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4RCY-UQxO1B",
        "outputId": "9c38d233-9833-43ba-cd6d-ecf6cb0dfae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8 libcudnn8-dev\n",
            "2 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 704 MB of archives.\n",
            "After this operation, 2,625 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8-dev 8.5.0.96-1+cuda11.7 [356 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.5.0.96-1+cuda11.7 [347 MB]\n",
            "Fetched 704 MB in 23s (30.3 MB/s)\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8-dev_8.5.0.96-1+cuda11.7_amd64.deb ...\n",
            "Unpacking libcudnn8-dev (8.5.0.96-1+cuda11.7) over (8.0.5.39-1+cuda11.1) ...\n",
            "Preparing to unpack .../libcudnn8_8.5.0.96-1+cuda11.7_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.5.0.96-1+cuda11.7) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.5.0.96-1+cuda11.7) ...\n",
            "Setting up libcudnn8-dev (8.5.0.96-1+cuda11.7) ...\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/include/x86_64-linux-gnu/cudnn_v7.h because link group libcudnn is broken\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in manual mode\n"
          ]
        }
      ],
      "source": [
        "# Need updated package for libcudnn8 so that step 7 doesn't trigger an error\n",
        "!apt install --allow-change-held-packages libcudnn8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RAxXN6EYMKFZ"
      },
      "outputs": [],
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "# Check tensorflow version\n",
        "# print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-J7whqrkIl"
      },
      "source": [
        "Install the Tensorflow 2 [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi28cqGGFWnY",
        "outputId": "69d720fc-039f-4bfe-855b-bc1777ffc623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3451, done.\u001b[K\n",
            "remote: Counting objects: 100% (3451/3451), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2891/2891), done.\u001b[K\n",
            "remote: Total 3451 (delta 891), reused 1418 (delta 503), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3451/3451), 46.85 MiB | 21.72 MiB/s, done.\n",
            "Resolving deltas: 100% (891/891), done.\n",
            "Checking out files: 100% (3125/3125), done.\n"
          ]
        }
      ],
      "source": [
        "# uncomment the next line if you want to delete an existing models directory\n",
        "# !rm -rf ./models/\n",
        "\n",
        "# clone the Tensorflow Model Garden\n",
        "!git clone --depth 1 https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwdsBdGhFanc",
        "outputId": "6522e152-973b-41d0-c5ed-65563bed1b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 53.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
            "Collecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 56.2 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0.66)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.47.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.7.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 53.7 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 46.5 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.9.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694955 sha256=efb672dbb93c53b07c25716b111e7e8a614efce6bfe6d9c57d1e8a4901dce110\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9qjb6qcg/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=584b2dda7fba4bd2309c20e7a92e939f6676c5ac83b7bc09fcfaedb72a5b9177\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=3533e12da7c8903a650d1e72c85b7be972feb0c97e92d498156c79ed297d354f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=c48708818920682cc008581890c054f5ee178e08f6babf514e9d8e7ab8c4ca6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=942d2283e874b706e710721418b2984232c0de6a6947d279bf90d9f631981707\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=161f4ceb69c159ead3162c32e7d3b917785224393ae471a8731d214d0644303d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, portalocker, docopt, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.2.0\n",
            "    Uninstalling pymongo-4.2.0:\n",
            "      Successfully uninstalled pymongo-4.2.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.40.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.0 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 orjson-3.7.12 portalocker-2.5.1 proto-plus-1.22.0 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.17.1 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# install the Object Detection API\n",
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tUtyyVrkIt"
      },
      "source": [
        "### 2.2 Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW7YShaj2iXN",
        "outputId": "6814e340-bd64-41b8-c101-79ab880f59e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dfply\n",
            "  Downloading dfply-0.3.3-py3-none-any.whl (612 kB)\n",
            "\u001b[K     |████████████████████████████████| 612 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dfply) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dfply) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->dfply) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->dfply) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->dfply) (1.15.0)\n",
            "Installing collected packages: dfply\n",
            "Successfully installed dfply-0.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install dfply\n",
        "from dfply import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uZcqD4NLdnf4"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7YihOFxxrkIw"
      },
      "outputs": [],
      "source": [
        "# import the label map utility module\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "# import module for reading and updating configuration files.\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "# import module for visualization. use the alias `viz_utils`\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# import module for building the detection model\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "# import module for utilities in Colab\n",
        "from object_detection.utils import colab_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcPfo571mnzz"
      },
      "source": [
        "### 2.3 Import and Clean Label Data\n",
        "We need to grab the Label Map for the classes from GitHub (StringIntLabelMap.pbtxt). We'll then define a few dictionaries for the 9 classes in the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cCjMj0_OsR7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c9045a-c83a-4db2-a40f-1711b31a3679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-18 18:00:39--  https://raw.githubusercontent.com/fredthefish/OddyTest/main/StringIntLabelMap.pbtxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 360 [text/plain]\n",
            "Saving to: ‘dir/StringIntLabelMap.pbtxt’\n",
            "\n",
            "\rStringIntLabelMap.p   0%[                    ]       0  --.-KB/s               \rStringIntLabelMap.p 100%[===================>]     360  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-18 18:00:39 (14.9 MB/s) - ‘dir/StringIntLabelMap.pbtxt’ saved [360/360]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load label map from file\n",
        "# Function found here: https://github.com/tensorflow/models/blob/master/research/object_detection/utils/label_map_util.py\n",
        "!wget https://raw.githubusercontent.com/fredthefish/OddyTest/main/StringIntLabelMap.pbtxt -P dir\n",
        "label_map = label_map_util.load_labelmap('/content/dir/StringIntLabelMap.pbtxt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qnY4YTNx6JA",
        "outputId": "7034715a-1da6-469d-a6fa-c71ca54899fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ag-P': 1,\n",
              " 'Ag-T': 2,\n",
              " 'Ag-U': 3,\n",
              " 'Cu-P': 4,\n",
              " 'Cu-T': 5,\n",
              " 'Cu-U': 6,\n",
              " 'Pb-P': 7,\n",
              " 'Pb-T': 8,\n",
              " 'Pb-U': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Convert to dictionary\n",
        "label_dict = label_map_util.get_label_map_dict(label_map,use_display_name=True)\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HWBqFVMcweF-"
      },
      "outputs": [],
      "source": [
        "# define a dictionary describing the corrosion classes\n",
        "category_index = {\n",
        "    1 : {\n",
        "        'id'  : 1, \n",
        "        'name': 'Ag-P'\n",
        "    },\n",
        "    2 : {\n",
        "        'id'  : 2,\n",
        "        'name': 'Ag-T'\n",
        "    },\n",
        "    3 : {\n",
        "        'id'  : 3,\n",
        "        'name': 'Ag-U'\n",
        "    },\n",
        "    4 : {\n",
        "        'id'  : 4,\n",
        "        'name': 'Cu-P'\n",
        "    },\n",
        "    5 : {\n",
        "        'id'  : 5,\n",
        "        'name': 'Cu-T'\n",
        "    },\n",
        "    6 : {\n",
        "        'id'  : 6,\n",
        "        'name': 'Cu-U'\n",
        "    },\n",
        "    7 : {\n",
        "        'id'  : 7,\n",
        "        'name': 'Pb-P'\n",
        "    },\n",
        "    8 : {\n",
        "        'id'  : 8,\n",
        "        'name': 'Pb-T'\n",
        "    },\n",
        "    9 : {\n",
        "        'id'  : 9,\n",
        "        'name': 'Pb-U'\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IPy7vfCCrkJF"
      },
      "outputs": [],
      "source": [
        "# Testing grabbing the categories\n",
        "# print(category_index[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DOkztZ0-Fytp"
      },
      "outputs": [],
      "source": [
        "# Specify the number of classes that the model will predict\n",
        "num_classes = 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgG_YT7UrkJQ"
      },
      "source": [
        "### 2.4 Configure the CNN Model & Build with Model Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gets the model config from github, builds the model, and imports the trained model checkpoint."
      ],
      "metadata": {
        "id": "uIArneXT9tXT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "59sEM6wXheJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18665644-37b1-4525-a4bb-d053c5ec15ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-18 18:00:39--  https://raw.githubusercontent.com/fredthefish/OddyTest/main/eff_det_d1_pipeline_5.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4435 (4.3K) [text/plain]\n",
            "Saving to: ‘dir/eff_det_d1_pipeline_5.config’\n",
            "\n",
            "\r          eff_det_d   0%[                    ]       0  --.-KB/s               \reff_det_d1_pipeline 100%[===================>]   4.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-18 18:00:39 (74.0 MB/s) - ‘dir/eff_det_d1_pipeline_5.config’ saved [4435/4435]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Clears old models\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# EfficientDet V3:\n",
        "!wget https://raw.githubusercontent.com/fredthefish/OddyTest/main/eff_det_d1_pipeline_5.config -P dir\n",
        "pipeline_config = '/content/dir/eff_det_d1_pipeline_5.config'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the configuration file into a dictionary\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)"
      ],
      "metadata": {
        "id": "mq41CM9PMl3F"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ps3AzqBvheJa"
      },
      "outputs": [],
      "source": [
        "# Read in the object stored at the key 'model' of the configs dictionary\n",
        "model_config = configs['model']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qfoRTeV_rkJT"
      },
      "outputs": [],
      "source": [
        "# Use the model_builder build function from the config above\n",
        "detection_model = model_builder.build(model_config = model_config, is_training = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEMnc0p2rHfz",
        "outputId": "1b9f1659-729b-4af8-d452-4c3b93672396"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch at 0x7f9450336290>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "detection_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the checkpoint from Google Drive.\n",
        "\n",
        "Note: do not point the checkpoint path at ckpt-49.index because we also need the checkpoint data file."
      ],
      "metadata": {
        "id": "RkXVvUm6-Iti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elkvDUUarkJg",
        "outputId": "614c72e1-4c52-42cd-e22c-01514bb773c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f93de0f8850>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#!wget https://raw.githubusercontent.com/fredthefish/OddyTest/main/ckpt-49.index -P dir\n",
        "# checkpoint_path = '/content/drive/MyDrive/Dissertation/models_workspace/MetCheckpoint/ckpt-49'\n",
        "\n",
        "# Define a checkpoint\n",
        "checkpoint = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "\n",
        "# Restore the checkpoint to the checkpoint path\n",
        "checkpoint.restore(checkpoint_path).expect_partial()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k6oFoxTrkJi"
      },
      "source": [
        "Run a dummy image through the model so that variables are created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MANTSP9LrkJi",
        "outputId": "45c84d85-7946-478c-e357-a7598bc0dbd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights restored!\n"
          ]
        }
      ],
      "source": [
        "# use the detection model's `preprocess()` method and pass a dummy image\n",
        "tmp_image, tmp_shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
        "\n",
        "# run a prediction with the preprocessed image and shapes\n",
        "tmp_prediction_dict = detection_model.predict(tmp_image, tmp_shapes)\n",
        "\n",
        "# postprocess the predictions into final detections\n",
        "tmp_detections = detection_model.postprocess(tmp_prediction_dict, tmp_shapes)\n",
        "\n",
        "print('Weights restored!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WuKybQgNrCES"
      },
      "outputs": [],
      "source": [
        "# Check on the shape of the model:\n",
        "# tmp_shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-GIbqkzrkJ_"
      },
      "source": [
        "### 2.5 Define Functions \n",
        "\n",
        "Processing an Image with the Neural Network, Cleaning the Outputs, and Saving Labelled Images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**plot_detections** for plotting bounding boxes on images"
      ],
      "metadata": {
        "id": "fCF4KXau-qkJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BMNWCNIaFYoV"
      },
      "outputs": [],
      "source": [
        "  def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "    \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "    Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "          and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "          this function assumes that the boxes to be plotted are groundtruth\n",
        "          boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "          category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "    \"\"\"\n",
        "    \n",
        "    image_np_with_annotations = image_np.copy()\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_annotations,\n",
        "        boxes,\n",
        "        classes,\n",
        "        scores,\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=30,\n",
        "        min_score_thresh=0.3,\n",
        "        line_thickness = 10)\n",
        "    \n",
        "    if image_name:\n",
        "        plt.imsave(image_name, image_np_with_annotations)\n",
        "    \n",
        "    else:\n",
        "        plt.imshow(image_np_with_annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load_image_into_numpy_array** turns a jpg into a numpy array"
      ],
      "metadata": {
        "id": "_CAqoNAb-yKW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jLLPPrJvh-fK"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Shape: (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args: path - a file path.\n",
        "    Returns: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    \n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data))\n",
        "    (im_width, im_height) = image.size\n",
        "    \n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load_image_set** loads a folder of images into variables for numpy arrays and tensors"
      ],
      "metadata": {
        "id": "2CBUlm2S-6Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_set(image_dir):\n",
        "    \"\"\"Load a folder of images, converts to numpy arrays, and then converts to tensors.\n",
        "    Args: \n",
        "      image_dir - a path to folder of training, validation, or test images. \n",
        "    Returns:\n",
        "      image_nps - numpy arrays for images\n",
        "      image_tensors - image tensors\n",
        "      files - file names from image_dir\n",
        "    \"\"\"\n",
        "    # Get a list of the files in the image folder\n",
        "    files = os.listdir(image_dir)\n",
        "    # Starting an empty list for the npy arrays\n",
        "    image_nps = []\n",
        "    # List for image tensors\n",
        "    image_tensors = []\n",
        "    # Iterate and load each image in the file\n",
        "    for idx, file in enumerate(files):\n",
        "        # define the path (string) for each image\n",
        "        image_path = os.path.join(image_dir,file)\n",
        "        # load image into numpy array and append to list\n",
        "        image_np = load_image_into_numpy_array(image_path)\n",
        "        image_nps.append(image_np)\n",
        "        # convert training image to tensor, add batch dimension, and add to list\n",
        "        image_tensors.append(tf.expand_dims(tf.convert_to_tensor(image_np, dtype=tf.float32), axis=0))\n",
        "        # Give a loading update every 5 images\n",
        "        if idx % 5 == 0:\n",
        "          print('Loading',str(idx),':',file)\n",
        "    print('Done Loading and Saving!')\n",
        "    return image_nps, image_tensors, files"
      ],
      "metadata": {
        "id": "8EQ5R5JJri6g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**detect** runs an image through the CNN and outputs the detections"
      ],
      "metadata": {
        "id": "AEhI10VJ_QfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9aXt-bodrkKA"
      },
      "outputs": [],
      "source": [
        "# Uncomment this decorator if you want to run inference eagerly\n",
        "@tf.function\n",
        "def detect(input_tensor):\n",
        "    \"\"\"Run the neural network on an input image.\n",
        "\n",
        "    Args:\n",
        "    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\n",
        "      Note that height and width can be anything since the image will be\n",
        "      immediately resized according to the needs of the model within this\n",
        "      function.\n",
        "\n",
        "    Returns:\n",
        "    3 Tensors (`detection_boxes`, `detection_classes`, and `detection_scores`).\n",
        "    \"\"\"\n",
        "    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
        "    prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
        "    # use the detection model's postprocess() method to get the the final detections\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes) \n",
        "\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**detect_extract** gets the predicted classes, scores, and bounding boxes from the CNN detections"
      ],
      "metadata": {
        "id": "mINkOB-b_YHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_extract(input_tensor):\n",
        "    ''' Function to extract the predicted classes, scores, and bounding boxes'''\n",
        "\n",
        "    # Run neural network on image\n",
        "    detections = detect(input_tensor)\n",
        "\n",
        "    # Get predicted classes, scores, and boxes\n",
        "    class_array = detections['detection_classes'][0].numpy().astype('int') + 1\n",
        "    det_scores = detections['detection_scores'][0].numpy()\n",
        "    det_boxes = detections['detection_boxes'][0].numpy()\n",
        "\n",
        "    return class_array, det_scores, det_boxes"
      ],
      "metadata": {
        "id": "uk4lX2vqmeD2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**intersection_over_union** calculates the Intersection Over Union (IOU) for two bounding boxes"
      ],
      "metadata": {
        "id": "4Ejz5kcv_ifx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hjhC0NGndSs3"
      },
      "outputs": [],
      "source": [
        "def intersection_over_union(pred_box, true_box):\n",
        "    # Split the predicted box array into separate values: (ymin, xmin, ymax, xmax)\n",
        "    ymin_pred, xmin_pred, ymax_pred, xmax_pred = np.split(pred_box, 4)\n",
        "    ymin_true, xmin_true, ymax_true, xmax_true = np.split(true_box, 4)\n",
        "\n",
        "    smoothing_factor = 1e-10\n",
        "\n",
        "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
        "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
        "    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n",
        "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
        "\n",
        "    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
        "    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n",
        "\n",
        "    overlap_area = np.maximum((xmax_overlap - xmin_overlap), 0)  * np.maximum((ymax_overlap - ymin_overlap), 0)\n",
        "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
        "    \n",
        "    iou = (overlap_area + smoothing_factor) / (union_area + smoothing_factor)\n",
        "\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**chooseBoxes** reduces the number of bounding box predictions to just the highest scoring ones that don't overlap"
      ],
      "metadata": {
        "id": "F0R2yemk_r8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chooseBoxes(image_tensor):\n",
        "  ''' This function finds the highest scoring boxes that do not overlap with eachother for plotting \n",
        "  Args: image_tensors - one image in tensor format\n",
        "  Returns: reduced lists of predicted classes, scores, and bounding boxes\n",
        "  '''\n",
        "\n",
        "  # Run the image through the neural network to get predictions\n",
        "  det_classes, det_scores, det_boxes = detect_extract(image_tensor)\n",
        "\n",
        "  # Create a list of boxes to keep for plotting\n",
        "  keep_list = [0]\n",
        "  # Iterate over all the predicted boxes\n",
        "  for i in range(len(det_scores)):\n",
        "      # Ignore any boxes with scores of 0\n",
        "      if det_scores[i] == 0:\n",
        "        break\n",
        "      # The first box (i = 0) will always be included because it has the highest score\n",
        "      if i == 0 :\n",
        "        continue\n",
        "      # Create list to store the IOUs of box i\n",
        "      ious = []\n",
        "      # Need to find intersections with all the boxes currently being 'kept' for display on images\n",
        "      for j in keep_list:\n",
        "        iou = intersection_over_union(det_boxes[i],det_boxes[j])\n",
        "        # print('Box', str(i),'has iou with box',str(j),': ',iou)\n",
        "        ious.append(iou)\n",
        "      # Sorts the IOUs to find the highest IOU between box i and the boxes in the keep list\n",
        "      ious.sort(reverse = True)\n",
        "      # If the largest IOU is less than 0.2 (poor fit with all other boxes), add this box to the list\n",
        "      if ious[0] < 0.2:\n",
        "          keep_list.append(i)\n",
        "          # print('Added box', str(i),'to keep list')\n",
        "      \n",
        "  # Return only the necessary boxes\n",
        "  return det_classes[keep_list], det_scores[keep_list], det_boxes[keep_list]"
      ],
      "metadata": {
        "id": "ea4joe6ksWlH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**scanImage** runs an image through the CNN and saves an image of the best bounding boxes"
      ],
      "metadata": {
        "id": "P2wXOfcN_8N0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Kp2w7GdZXojC"
      },
      "outputs": [],
      "source": [
        "def scanImage(image_nps, image_tensors, files, i):\n",
        "  ''' Runs an image through the CNN, finds only the best bounding boxes (chooseBoxes function),\n",
        "  and plots and saves the image labelled with predictions.\n",
        "  Args: \n",
        "  image_nps - numpy image stack.\n",
        "  image_tensors - tensor image stack\n",
        "  files - file names of images for saving. \n",
        "  i - number of image\n",
        "  Returns: the predicted classes, bounding boxes, and scores (class_array, det_boxes, det_scores)\n",
        "  '''\n",
        "\n",
        "  # Get the predicted bounding boxes from the neural network that don't overlap\n",
        "  class_array, det_scores, det_boxes = chooseBoxes(image_tensors[i])\n",
        "\n",
        "  # Define the figure size\n",
        "  fig = plt.figure(figsize=(80, 50))\n",
        "  # Use the plot_detections function to draw the ground truth boxes\n",
        "  plot_detections(\n",
        "      image_nps[i],\n",
        "      det_boxes,\n",
        "      class_array,\n",
        "      det_scores,\n",
        "      category_index = category_index,\n",
        "  )\n",
        "  #Save \n",
        "  plt.savefig(\"/content/result_directory/\"+files[i].replace(\"jpg\", \"png\"))\n",
        "  plt.close(fig)\n",
        "\n",
        "  # Print an update every 5 images, and for the first and last images.\n",
        "  if (i == 0) or ((i+1) % 5 == 0) or ((i+1) == len(image_nps)):\n",
        "    print(str(i+1)+\"/\"+str(len(image_nps))+\": content/result_directory/\"+files[i].replace(\"jpg\", \"png\"))\n",
        "\n",
        "  return class_array, det_boxes, det_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**findMetals** creates a dataframe of the predicted classes (2 per metal type)"
      ],
      "metadata": {
        "id": "kvq7ECwdAf-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findMetals(pred_boxes, class_array, files, i):\n",
        "  '''\n",
        "  Args: \n",
        "  pred_boxes: dataframe for the predictions\n",
        "  class_array: array of classes for bounding boxes\n",
        "  files - file names of images for saving. \n",
        "  i - number of image\n",
        "\n",
        "  Returns:\n",
        "  Updated pred_boxes dataframe with the classes from 1-9 or 0 for NA values\n",
        "  '''\n",
        "\n",
        "  # Add filename to dataframe\n",
        "  predBoxes.at[i,'FileName']  = files[i].replace('jpg','png')\n",
        "\n",
        "  # Finding silver predictions and adding to dataframe\n",
        "  Ag = class_array[class_array <= 3]\n",
        "  if len(Ag) == 0:\n",
        "    # If no silver predicted, leave as 0's and give warning message\n",
        "    print('No silver coupons detected in file',files[i])\n",
        "  elif len(Ag) == 1:\n",
        "    # If only one silver, add to first column\n",
        "    predBoxes.iloc[i,1] = Ag[0]\n",
        "  else:\n",
        "    # If two or more silver, just grab the first two\n",
        "    predBoxes.iloc[i,1:3] = Ag[0:2]\n",
        "  # Finding copper predictions and adding to dataframe\n",
        "  Cu = class_array[(class_array > 3) & (class_array <= 6)]\n",
        "  if len(Cu) == 0:\n",
        "    print('No copper coupons detected in file',files[i])\n",
        "  elif len(Cu) == 1:\n",
        "    predBoxes.iloc[i,3]  = Cu[0]\n",
        "  else:\n",
        "    predBoxes.iloc[i,3:5] = Cu[0:2]\n",
        "  # Finding lead predictions and adding to dataframe\n",
        "  Pb = class_array[class_array >= 7]\n",
        "  if len(Pb) == 0:\n",
        "    print('No lead coupons detected in file',files[i])\n",
        "  elif len(Pb) == 1:\n",
        "    predBoxes.iloc[i,5]  = Pb[0]\n",
        "  else:\n",
        "    predBoxes.iloc[i,5:7] = Pb[0:2]\n",
        "\n",
        "  return predBoxes"
      ],
      "metadata": {
        "id": "-IBmwOzCEtZa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JgWLFtxh7mK"
      },
      "source": [
        "# Get Model Output\n",
        "\n",
        "This code will give you the output files."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Convert Images, Process Them, and Output Results\n",
        "\n",
        "This section processes the uploaded through the neural network, and saves the predictions both as images and a csv file.\n",
        "\n",
        "It then runs the scanImage function to process the image through the neural network. The chooseBoxes function is called to prevent overlapping bounding boxes from being presented.\n",
        "\n",
        "The scanImage function will save the Oddy test images with the bounding boxes. It will make the files in the result_directory folder."
      ],
      "metadata": {
        "id": "Dhrz23OJBa2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Set Up for Images and Dataframe for Classes"
      ],
      "metadata": {
        "id": "snA1REiNIfyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section starts by converting the uploaded images to numpy and tensor files."
      ],
      "metadata": {
        "id": "GbbWWaHuBTx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets npy and tensors versions of images\n",
        "image_nps, image_tensors, files = load_image_set(\"/content/input_images\")"
      ],
      "metadata": {
        "id": "pK_cZ3O-o6wU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa14506-a8da-47ea-8d8f-f1e607db8276"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 0 : 620px-Sensuede2050_422_20141205.jpg\n",
            "Done Loading and Saving!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets a count of the number of uploaded images\n",
        "count = len(image_tensors)\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcqK3MA_ts5q",
        "outputId": "abb8d293-0b4f-47bf-98c0-09414b38446d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dataframe to store the predicted classes."
      ],
      "metadata": {
        "id": "dEE82S7zBf_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating empty data frame to store the classes outputted by the model for csv file\n",
        "z = [0] * count\n",
        "blank_row = {'FileName': ['']*count, 'Ag1': z, 'Ag2': z, 'Cu1': z, 'Cu2': z, 'Pb1': z, 'Pb2': z}\n",
        "predBoxes = pd.DataFrame(blank_row)"
      ],
      "metadata": {
        "id": "be4naZYj6LDm"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Process Your Images\n",
        "Keep an eye on the logs below, as they may show when the model has made errors, such as not detecting any lead coupons for a particular image."
      ],
      "metadata": {
        "id": "saRxSlqQIkwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each image to save class info and labelled images\n",
        "for i in range(count):\n",
        "   # Run the scan image function to save images with the bounding boxes\n",
        "   class_array, det_boxes, det_scores = scanImage(image_nps, image_tensors, files, i)\n",
        "   # Run the findMetals function to get the class data formatted as a dataframe\n",
        "   predBoxes = findMetals(predBoxes, class_array, files, i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITdfSnKFuIS6",
        "outputId": "441c0dc1-6dfc-4f6d-c1a1-28f800a592cd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5: content/result_directory/620px-Sensuede2050_422_20141205.png\n",
            "No silver coupons detected in file 560px-Sensuederain2004_418_20141205.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 27 calls to <function detect at 0x7f93c72fd320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5: content/result_directory/608px-Sensuede2064_424_20141205.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.3 Save CSV file of predictions and download zipped folder of images and csv file\n",
        "\n",
        "Depending on how many images you uploaded, this could take a few minutes to download the zip folder."
      ],
      "metadata": {
        "id": "x5-qiiAcJlWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A dictionary to convert class integers to P/T/U ratings with additional NA rating\n",
        "reverse_dict = {0:'N/A',1:'Ag-P', 2:'Ag-T', 3:'Ag-U', 4:'Cu-P', 5:'Cu-T', 6:'Cu-U', 7:'Pb-P', 8:'Pb-T', 9:'Pb-U'}\n",
        "# Mapping classes for ground truth and predicted classes\n",
        "for i in [1,2,3,4,5,6]:\n",
        "  # Map the label dictionary to a column to populate the corresponding class integer values\n",
        "  # https://kanoki.org/2019/04/06/pandas-map-dictionary-values-with-dataframe-columns/\n",
        "  predBoxes.iloc[:,i] = predBoxes.iloc[:,i].map(reverse_dict)"
      ],
      "metadata": {
        "id": "7_GvBuw75oxi"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predBoxes = predBoxes.reindex(columns=['FileName','Cu1','Cu2','Ag1','Ag2','Pb1','Pb2'])\n",
        "predBoxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-P72ZN4n_Lqg",
        "outputId": "53e54aec-2788-4a4a-8773-6a80af84e0a7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              FileName   Cu1   Cu2   Ag1   Ag2   Pb1   Pb2\n",
              "0      620px-Sensuede2050_422_20141205  Cu-P   N/A  Ag-T  Ag-T  Pb-U  Pb-U\n",
              "1         593px-Sensuede9_420_20141205  Cu-U  Cu-U  Ag-T  Ag-U  Pb-U   N/A\n",
              "2  560px-Sensuederain2004_418_20141205  Cu-U  Cu-U   N/A   N/A  Pb-U  Pb-P\n",
              "3      608px-Sensuede2081_426_20141205  Cu-U  Cu-U  Ag-U   N/A  Pb-U  Pb-U\n",
              "4      608px-Sensuede2064_424_20141205  Cu-U  Cu-U  Ag-T  Ag-T  Pb-U  Pb-U"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad169f5a-3613-4cb4-a977-2a2482b304d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>Cu1</th>\n",
              "      <th>Cu2</th>\n",
              "      <th>Ag1</th>\n",
              "      <th>Ag2</th>\n",
              "      <th>Pb1</th>\n",
              "      <th>Pb2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>620px-Sensuede2050_422_20141205</td>\n",
              "      <td>Cu-P</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Ag-T</td>\n",
              "      <td>Ag-T</td>\n",
              "      <td>Pb-U</td>\n",
              "      <td>Pb-U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>593px-Sensuede9_420_20141205</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Ag-T</td>\n",
              "      <td>Ag-U</td>\n",
              "      <td>Pb-U</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>560px-Sensuederain2004_418_20141205</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Pb-U</td>\n",
              "      <td>Pb-P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>608px-Sensuede2081_426_20141205</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Ag-U</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Pb-U</td>\n",
              "      <td>Pb-U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>608px-Sensuede2064_424_20141205</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Cu-U</td>\n",
              "      <td>Ag-T</td>\n",
              "      <td>Ag-T</td>\n",
              "      <td>Pb-U</td>\n",
              "      <td>Pb-U</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad169f5a-3613-4cb4-a977-2a2482b304d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad169f5a-3613-4cb4-a977-2a2482b304d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad169f5a-3613-4cb4-a977-2a2482b304d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predBoxes.to_csv('result_directory/OddyTestPredictions.csv', index = False, index_label=False)  "
      ],
      "metadata": {
        "id": "hHiVkHXRCE2M"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!rm /content/result_directory.zip\n",
        "!zip -r /content/result_directory.zip /content/result_directory/\n",
        "files.download(\"/content/result_directory.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "MedjcN5e5vYN",
        "outputId": "19ba204b-cc2e-45fe-f304-3f6d27e337e1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/result_directory/ (stored 0%)\n",
            "  adding: content/result_directory/560px-Sensuederain2004_418_20141205.png (deflated 16%)\n",
            "  adding: content/result_directory/OddyTestPredictions.csv (deflated 56%)\n",
            "  adding: content/result_directory/620px-Sensuede2050_422_20141205.png (deflated 15%)\n",
            "  adding: content/result_directory/608px-Sensuede2081_426_20141205.png (deflated 15%)\n",
            "  adding: content/result_directory/593px-Sensuede9_420_20141205.png (deflated 15%)\n",
            "  adding: content/result_directory/608px-Sensuede2064_424_20141205.png (deflated 15%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_70f66595-4924-429f-9cf8-98f4c38a6678\", \"result_directory.zip\", 2764613)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hLxVsAd06q3F",
        "rAGbawHa82L4",
        "vPs64QA1Zdov",
        "21tUtyyVrkIt",
        "tcPfo571mnzz",
        "LgG_YT7UrkJQ",
        "0JgWLFtxh7mK"
      ],
      "name": "Visualizing Box Labels",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}